{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"advertising_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataframe in following 5 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"deviceType\"] = df[\"deviceType\"].astype('category')\n",
    "df[\"day\"] = df[\"day\"].astype('category')\n",
    "df[\"case_id\"] = df[\"case_id\"].astype('category')\n",
    "df[\"countryId\"] = df[\"countryId\"].astype('category')\n",
    "df[\"companyId\"] = df[\"companyId\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the column \"deviceType\" to check its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(df['deviceType'], df['y'])\n",
    "ax.set_xlabel('deviceType')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most important features relative to target\n",
    "print(\"Find most important features relative to target\")\n",
    "corr = df.corr()\n",
    "corr.sort_values([\"y\"], ascending = False, inplace = True)\n",
    "print(corr.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the column impression and request have low corelation with the target varible,\n",
    "# we may check the corelation again if we combine both the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IR_Ratio'] = df['impression']/df['requests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the undired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop([ 'case_id','companyId','countryId','day', 'dow', 'impression', 'requests', 'ad_area', 'ad_ratio', 'ratio5'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the ouliers by keeping 1.5 standard deviation from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data):\n",
    "    u = np.mean(data)\n",
    "    s = np.std(data)\n",
    "    f1 = u - 1.5*s\n",
    "    f2 = u + 1.5*s\n",
    "    filtered = np.where(data.between(f1,f2),data, data.median())\n",
    "    return filtered\n",
    "\n",
    "df['ctr'] = reject_outliers(df['ctr'])\n",
    "df['price1'] = reject_outliers(df['price1'])\n",
    "df['price2'] = reject_outliers(df['price2'])\n",
    "df['price3'] = reject_outliers(df['price3'] )\n",
    "df['viewability'] = reject_outliers(df['viewability'] )\n",
    "df['ratio1'] = reject_outliers(df['ratio1'])\n",
    "df['ratio2'] = reject_outliers(df['ratio2'])\n",
    "df['ratio3'] = reject_outliers(df['ratio3'])\n",
    "df['ratio4'] = reject_outliers(df['ratio4'])\n",
    "df['y'] = reject_outliers(df['y'])\n",
    "df['cpc'] = reject_outliers(df['cpc'])\n",
    "df['IR_Ratio'] = reject_outliers(df['IR_Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide variab;es into feature and lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df[['deviceType', 'price1', 'price2', 'price3','cpc', 'ctr', 'viewability', 'ratio1', 'ratio2', 'ratio3', 'ratio4','IR_Ratio']].values\n",
    "label=df[['y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "label_scaled = scaler.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the training and testing data, keeping 90% for testing and rest for training. I have futher splitted the train \n",
    "# data into validation and training data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_scaled, label_scaled, test_size = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for random forest importance, which shows lowest RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "# here we use n_estimators=100\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor \n",
    "    # make sure class attributes end with a \"_\"\n",
    "    # per scikit-learn convention to avoid errors\n",
    "    def __init__(self, n_features_=100):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestRegressor(n_estimators=10)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model, which calculates root mean squared error and mean absolute error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=999)\n",
    "\n",
    "pipe_RF = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('rf', rf_regressor)])\n",
    "\n",
    "depths = np.arange(1, 10)\n",
    "\n",
    "\n",
    "\n",
    "params_pipe_RF = {'rfi_fs__n_features_': [15],                  \n",
    "                  'rf__max_depth': depths,\n",
    "                   'rf__min_samples_split': [2,3,4,5,6]}\n",
    " \n",
    "\n",
    "\n",
    "gs_pipe_RF  = GridSearchCV(estimator=pipe_RF, \n",
    "                           param_grid=params_pipe_RF, \n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring= 'neg_mean_squared_error', \n",
    "                           verbose=1)\n",
    "\n",
    "gs_pipe_RF.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the best parameters of the model and the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_results_dt = np.sqrt(-cross_val_score(gs_pipe_RF, feature_scaled, target, scoring='neg_mean_squared_error'))\n",
    "print(\"RMSE: %0.2f (+/- %0.2f)\" % (cv_results_rf.mean(), cv_results_rf.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the dataset was divided in two parts i.e. train and test set, the following section \n",
    "# uses the same model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deploy = pd.read_csv(\"advertising_test.csv\", na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deploy[\"deviceType\"] = df_deploy[\"deviceType\"].astype('category')\n",
    "df_deploy[\"day\"] = df_deploy[\"day\"].astype('category')\n",
    "df_deploy[\"countryId\"] = df_deploy[\"countryId\"].astype('category')\n",
    "df_deploy[\"companyId\"] = df_deploy[\"companyId\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deploy['IR_Ratio'] = df_deploy['impression']/df_deploy['requests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deploy['ctr'] = reject_outliers(df_deploy['ctr'] )\n",
    "df_deploy['price1'] = reject_outliers(df_deploy['price1'])\n",
    "df_deploy['price2'] = reject_outliers(df_deploy['price2'])\n",
    "df_deploy['price3'] = reject_outliers(df_deploy['price3'])\n",
    "df_deploy['viewability'] = reject_outliers(df_deploy['viewability'])\n",
    "df_deploy['ratio1'] = reject_outliers(df_deploy['ratio1'])\n",
    "df_deploy['ratio2'] = reject_outliers(df_deploy['ratio2'])\n",
    "df_deploy['ratio3'] = reject_outliers(df_deploy['ratio3'])\n",
    "df_deploy['ratio4'] = reject_outliers(df_deploy['ratio4'])\n",
    "df_deploy['cpc'] = reject_outliers(df_deploy['cpc'])\n",
    "df_deploy['IR_Ratio'] = reject_outliers(df_deploy['IR_Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for all the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_deploy=df_deploy[['deviceType', 'price1', 'price2', 'price3','cpc', 'ctr', 'viewability', 'ratio1', 'ratio2', 'ratio3', 'ratio4','IR_Ratio']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_deploy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "features_df_deploy_scaled = scaler.fit_transform(features_df_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to visually inspect the pridicted value for y, I have created a dataframe prediction_df\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction = rf_predictor.predict(features_df_deploy_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df['y'] = prediction\n",
    "case_id = range(1, 1+len(prediction_df))\n",
    "prediction_df.insert(0, \"case_id\", case_id, True) \n",
    "prediction_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(\"prediction_google_ad.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
